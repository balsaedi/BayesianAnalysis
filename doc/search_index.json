[["index.html", "A Minimal Book Example Chapter 1 About 1.1 Usage 1.2 Render book 1.3 Preview book", " A Minimal Book Example John Doe 2025-03-23 Chapter 1 About This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). 1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book”, or from the R console: bookdown::serve_book() "],["introduction-to-bayesian-thinking.html", "Chapter 2 Introduction to Bayesian Thinking 2.1 Introduction 2.2 The Core Concept: Bayesian vs frequentist 2.3 Applications of Bayesian Thinking 2.4 Challenges References", " Chapter 2 Introduction to Bayesian Thinking 2.1 Introduction During the past thirty years, statistical analysis using Bayesian technique has evolved enormously and has become the powerful statistical methodology for making decision from data. It is not just a family of techniques but brings a new way of thinking to statistics, it provides a powerful framework for reasoning about uncertainty, making decisions, and updating beliefs in the face of new evidence. Bayesian thinking has become a cornerstone of modern statistics, engineering, medicine, social sciences, and data sciences, and underpins much of the developing fields of machine learning and artificial intelligence (AI). In simple terms, it’s an approach that enables you to adjust your critical thinking in reactively to new evidence. Critical thinking is an active and continuous process that requires an approach like Bayesians, constantly refining and updating our knowledge as new information emerges. In this chapter, we explore key differences between Bayesian thinking with the frequentist approaches, the Bayes’ rule, and the thinking around making Bayesian inferences. Further, we explore real - world example of applying Bayesian statistics to a scientific problem. 2.2 The Core Concept: Bayesian vs frequentist The frequentist approach of statistics determines the how event occurs within a certain time period and then predict future events using this information. There is (are) population parameter(s) considered fixed but unknown, but characterized from data be observed from small portion of the population. For example, the probability of an event occurring can be estimated by taking the proportion of the number of times the event would occur to the number of trials. This proportion and other parameters of interest such as mean and variances are fixed and unknown, but needs to be estimated. Uncertainties around these parameter estimates are quantified using \\(100(1-\\alpha)\\%\\) confidence intervals where \\(\\alpha\\) is commonly called significance level. In contrast, Bayesian thinking is based on the combination of the likelihood of the data and prior belief or evidence to get new insights or information about the events. At the heart of Bayesian thinking is Bayes’ theorem, a simple but profound principle that describes how to update our beliefs in response to new data.To define Bayes theorem formally, it is crucial to understand peculiar components to Bayesian statistics. The first component is the concept conditional probability. It is the probability of an event occurring (say Event \\(A\\)) given that another event (say Event \\(B\\)) has already occurred. It’s essentially the “probability of A happening given B has happened” represented as \\(p(B/A)\\) and it is important for updating beliefs. The second component is the concept of Prior distributions. It represent the distribution of the parameter values based on personal belief, prior knowledge, experience, or assumptions before observing any new data. For example, to estimate the probability of a fair coin landing heads up, and no information is given other than this, the prior or assumption might be that the probability of heads up is 0.5. This prior is commonly called uniform prior. However, if there is a reason to believe that the coin might be biased towards heads, one can choose a prior that reflects that belief, like a beta distribution. The other key compnent in Bayesian statistics is the concept of Likelihood distribution (often just referred to as the likelihood) represents how likely it is to observe the data given a specific set of parameters in a statistical model. It is a distribution function that describes the liklihood contribution of the observed data under different parameter values. The last component is the concept of posterior distribution which combines prior distribution and the likelihood using Bayes’ rule. Thus, the Bayes theorem is mathematically expressed as: \\[ p(\\theta | D) = \\frac{p(D | \\theta) p(\\theta)}{p(D)}, \\] Where: \\(p(D | \\theta)\\) describes the likelihood function, the probability of observing the data (D) given the parameter \\(\\theta\\) \\(p(\\theta)\\) is the prior distribution for the parameter \\(\\theta\\) describing the initial belief about the parameter before any data is observed. \\(p(D)\\) is the normalizing constant. \\(p(\\theta | D)\\) is the posterior distribution of the parameter \\(\\theta\\) given the data. It represent the updated belief about a parameter \\(\\theta\\) after observing data $ D$. This equation encapsulates the Bayesian approach: starting with an initial belief (the prior), using evidence (the likelihood) to adjust that belief, and arriving at an updated belief (the posterior). The beauty of this process is that it allows the integration of both subjective prior knowledge and objective data, making it an ideal tool for reasoning under uncertainty. 2.2.1 Motivating Examples 2.2.1.1 Basketball shooting Let’s consider the example of shooting free throws in basketball. Suppose we define success as making the shot. Unlike a fair coin, we can’t assume a fixed probability for success, as it depends on the player’s skill, and other factors. Now, let’s observe a player taking n free throws and count how many they make, denoted as \\(y\\). Our goal is to estimate the player’s true free throw shooting percentage, \\(\\theta\\). A natural first guess is to use the proportion \\(y/n\\) as our estimate for \\(\\theta\\). But suppose a player takes \\(n = 4\\) free throws and misses all of them \\((y = 0)\\). Would it be reasonable to conclude that a player will never make a free throw \\((\\theta = 0/3 = 0)\\) in the future? Probably not. However, if the player shoots \\(n = 100\\) free throws and still never makes a single one \\((y = 0)\\), then we might reasonably conclude that their chances of making a shot are extremely low, if not zero. 2.2.1.2 Covid-19 testing Consider a more practical medical scenario: estimating the probability that a person tests positive for COVID-19. Suppose we define success as a positive test result. Unlike a fair coin, we don’t know the exact probability of testing positive for any given individual, as it depends on factors like recent exposure, symptoms, and the accuracy of the test. Now, let’s test \\(n\\) individuals and count how many receive a positive result, denoted as \\(y\\). Our goal is to estimate the true probability \\(\\theta\\) of a positive test. Probably our first intuition is to use the proportion of positive test \\(y/n\\) as an estimate for \\(\\theta\\), the true population parameter. But suppose we test \\(n = 5\\) individuals, and none of them test positive \\((y = 0)\\). Would it be reasonable to conclude that COVID-19 is not present in the population \\((\\theta = 0/5 = 0)\\) just based on this small sample? Clearly not. However, if we test \\(n = 1000\\) individuals and still see zero positive cases \\((y = 0)\\), we might start to suspect that COVID-19 is no longer circulating in the population, or that the test is faulty. The two motivating examples illustrates why, in addition to estimating the most likely value of \\(\\theta\\), we must also account for uncertainty in our estimates. The process of determining the most probable parameter values while quantifying uncertainty is known as statistical inference. 2.2.1.3 Pew research survey: Science knowledge A Pew research center conducted a survey of What Americans Know About Science with the question: “Based on what you have heard or read, which of the following two statements best describes the scientific method?” The response to this question was summarized in Table 1.1 by the educational level of the respondents. Table 2.1: Science Knowledge by Education Level HS College Bachelors Postgrad Total Iterative 913 838 686 570 3007 Unchanging 277 200 117 60 654 Not sure 408 213 81 40 742 Total 1598 1251 884 670 4403 What percent of those with a postgraduate degree that the scientific method is “iterative”? How is this related to the values provided? Given that a person correctly answers a science question, what is the probability that they have a postgrad education level? Solution Create the data frame data &lt;- data.frame( Response = c(&quot;Iterative&quot;, &quot;Unchanging&quot;, &quot;Not sure&quot;, &quot;Total&quot;), HS = c(913, 277, 408, 1598), college = c(838, 200, 213, 1251), Bachelors = c(686, 117, 81, 884), Postgrad = c(570, 60, 40, 670), Total = c(3007, 654, 742, 4403) ) head(data) ## Response HS college Bachelors Postgrad Total ## 1 Iterative 913 838 686 570 3007 ## 2 Unchanging 277 200 117 60 654 ## 3 Not sure 408 213 81 40 742 ## 4 Total 1598 1251 884 670 4403 We want to calculate the percentage of individuals with a postgraduate degree who believe that the scientific method is “iterative”. The formula is: \\[ \\text{Percentage} = \\frac{\\text{Number of Postgrad people who think scientific method is iterative}}{\\text{Total number of Postgrad people}} \\times 100 \\] From the data: - The number of Postgrad individuals who think the scientific method is “iterative” is 570. - The total number of Postgrad individuals is 670. # Number of Postgrad individuals who think the scientific method is iterative iterative_postgrad &lt;- data$Postgrad[1] # Total number of Postgrad individuals total_postgrad &lt;- data$Postgrad[4] # Calculate the percentage percentage_iterative_postgrad &lt;- (iterative_postgrad / total_postgrad) * 100 percentage_iterative_postgrad ## [1] 85.07463 The percentage of individuals with a postgraduate degree who think the scientific method is “iterative” is approximately 85.0%. We want to compute the probability that a person has a postgrad education, given that they correctly answered a science question. This can be modeled using Bayes’ Rule. The formula for Bayes’ Rule is: \\[ P(\\text{Postgrad} | \\text{Correct Answer}) = \\frac{P(\\text{Correct Answer} | \\text{Postgrad}) P(\\text{Postgrad})}{P(\\text{Correct Answer})} \\] Where: \\(P(\\text{Postgrad})\\) = Prior probability of having a postgrad education \\(P(\\text{Correct Answer} | \\text{Postgrad})\\) = Probability of correctly answering a question given postgrad education \\(P(\\text{Correct Answer})\\) = Total probability of correctly answering a question (across all education levels) # Calculate the probabilities postgrad_total &lt;- sum(data$Postgrad[1:3]) total_answers &lt;- sum(data$Total[1:3]) # P(Postgrad) = probability of postgrad education P_postgrad &lt;- postgrad_total / data$Total[4] # P(Correct Answer | Postgrad) = probability of answering correctly given postgrad P_correct_given_postgrad &lt;- data$Postgrad[1] / data$Postgrad[4] # P(Correct Answer) = total probability of answering correctly P_correct &lt;- sum(data$Postgrad[1:3] + data$college[1:3] + data$Bachelors[1:3] + data$HS[1:3]) / data$Total[4] # Apply Bayes&#39; Rule P_postgrad_given_correct &lt;- (P_correct_given_postgrad * P_postgrad) / P_correct P_postgrad_given_correct ## [1] 0.1294572 2.2.2 Likelihood function The likelihood function quantifies the likelihood distribution of the observed data given the parameter. It describes the probability of observing the data given a particular set of parameters. It is denoted as \\(p(y | \\theta)\\), where \\(y\\) represents the observed data, and \\(\\theta\\) represents the parameters you’re estimating. Example 1.1: If we are trying to model the relationship between a drug and patient recovery, the likelihood would capture the probability of observing the patients’ recovery outcomes given the dosage and treatment conditions. Example 1.2: Suppose you conduct a survey where 8 out of 10 people express interest in a new product. You might model this as a Binomial distribution. The likelihood function would describe the probability of observing 8 successes (interest) out of 10 trials, given a probability \\(\\theta\\) of success. \\[ L(\\theta | y) = \\binom{10}{8} \\theta^8 (1 - \\theta)^2. \\] Example 1.3: Continuing the Basketball throwing example, if \\(\\theta\\) represent the probability of a successful free throws in \\(n\\) consecutive throws. Assuming each shot is independent, the number of successful shots \\(y\\) follows a Binomial distribution: \\[ y|\\theta \\sim Bin(n, \\theta) \\] with the likelihood function \\[ L(\\theta |y, n) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}. \\] Given the structure of the data, \\(p(y|\\theta)\\) specifies parametric model for the data \\((y)\\) given the parameter \\(\\theta\\). The likelihood function is not a probability density function rather it specifies the uncertainty about \\(\\theta\\). Example 1.4: In a group of students, there are 7 out of 30 that are left-handed. Define the likelihood function Solution - Let “y” denote the random variable representing the observed data that we are working with the problem. Here, the random variable is the number of left-handed students in the group. The number of students (n) would be 18, and the number of left-handed students would be 7. Let \\(\\theta\\) denote the proportion of left-handed students in the population. Here, \\(\\theta\\) is the true probability that any given student in the population is left-handed. Thus, the random variable \\(y\\) as: \\[ y \\sim Bin(n=30, \\theta),\\,\\, \\] and the likelihood function of \\(\\theta\\) given the data \\(y\\) is: \\[ L(\\theta|y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}. \\] Example 1.5: “What is the likelihood that a person has a postgraduate education given that they believe the scientific method is ‘iterative’?” We are interested in the probability that a person has a postgraduate degree, given that they believe the scientific method is iterative. We want to compute: \\[ P(\\text{Postgrad} | \\text{Iterative}) = \\frac{P(\\text{Iterative} | \\text{Postgrad}) \\cdot P(\\text{Postgrad})}{P(\\text{Iterative})} \\] Where: \\(P(\\text{Iterative} | \\text{Postgrad})\\) is the probability that a postgraduate individual believes the method is iterative. \\(P(\\text{Postgrad})\\) is the prior probability of having a postgraduate education. \\(P(\\text{Iterative})\\) is the probability that a person believes the method is iterative. # Calculate individual probabilities P_iterative_given_postgrad &lt;- data$Postgrad[1] / data$Postgrad[4] P_postgrad &lt;- data$Postgrad[4] / data$Total[4] P_iterative &lt;- sum(data$Postgrad[1] + data$college[1] + data$Bachelors[1] + data$HS[1]) / data$Total[4] # Calculate the likelihood likelihood_postgrad_given_iterative &lt;- (P_iterative_given_postgrad * P_postgrad) / P_iterative likelihood_postgrad_given_iterative ## [1] 0.1895577 The likelihood that a person has a postgraduate education given that they believe the scientific method is iterative is approximately 0.19. 2.2.3 Prior distributions: \\(p(\\theta)\\) The foundation for Bayesian thinking is specifying or identifying prior distribution for the parameter of interest before observing any data. It incorporate your beliefs, knowledge, assumptions, or expectations about the parameter of interest in the analysis. These assumption are subjective in nature because the degree of belief can vary from person to person. Subjective priors are often used when there is prior knowledge that is highly relevant to the analysis. However, this definition is highly subjective, and assumes that all priors are subjective priors. Not everyone concur with this idea as one desired to obtain results that are objectively valid. This can be achieved by specifying prior distribution that have minimal impact on the posterior distribution. Such distributions are called objective or noninformative priors (see the next section). The difference between objective and subjective priors is due to the nature of prior knowledge or degree of beliefs. 2.2.4 Posterior distributions Once the prior and likelihood are combined, Bayes’ theorem yields the posterior distribution, \\(p(\\theta | y)\\), which represents the updated belief about the hypothesis given the data. Mathematically, it is given by Bayes’ Theorem: \\[ p(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{p(y)} \\] Where \\(p(\\theta |y)\\), \\(p(y | \\theta)\\), and \\(p(\\theta)\\) are as defined above. \\(p(\\text{y})\\) is the marginal likelihood, also known as the evidence, which normalizes the result to ensure the posterior sums to 1 over all possible values of $ $, and it is constant, i.e., \\(p(y) = \\int_{\\theta}p(y|\\theta) p(\\theta) d\\theta\\). Thus, the above equation can be expressed as \\[ p(\\theta|y) \\propto p(y|\\theta) \\times p(\\theta). \\] Equivalently in words, it can be expressed as \\[ Posterior \\propto Likelihood \\times Prior. \\] The posterior can be interpreted as a new probability distribution over all possible values of the parameter, reflecting both the prior knowledge and the evidence provided by the data. Example 1.5: Calculate the posterior probabilities for each perception (iterative, unchanging, not sure) assuming the prior probabilities for the American adult’s perception of the scientific method. Solution: We are tasked with calculating the posterior probabilities for different perceptions about the scientific method (iterative, unchanging, not sure), assuming prior probabilities for American adults’ perceptions are as follows: \\(P(\\text{Iterative}) = 0.70\\) \\(P(\\text{Unchanging}) = 0.14\\) \\(P(\\text{Not Sure}) = 0.16\\) We will calculate the posterior probability for each perception using Bayes’ Theorem. The formula is: \\[ P(\\text{Response} | \\text{Education Level}) = \\frac{P(\\text{Education Level} | \\text{Response}) \\cdot P(\\text{Response})}{P(\\text{Education Level})} \\] Where: \\(P(\\text{Response})\\) is the prior probability of the perception. \\(P(\\text{Education Level} | \\text{Response})\\) is the likelihood of an education level given the response. \\(P(\\text{Education Level})\\) is the total probability of a particular education level across all responses. P_iterative &lt;- 0.70 P_unchanging &lt;- 0.14 P_notsure &lt;- 0.16 # Likelihoods P_iterative_HS &lt;- data$HS[1] / data$Total[1] P_iterative_college &lt;- data$college[1] / data$Total[2] P_iterative_Bachelors &lt;- data$Bachelors[1] / data$Total[3] P_iterative_Postgrad &lt;- data$Postgrad[1] / data$Total[4] P_unchanging_HS &lt;- data$HS[2] / data$Total[1] P_unchanging_college &lt;- data$college[2] / data$Total[2] P_unchanging_Bachelors &lt;- data$Bachelors[2] / data$Total[3] P_unchanging_Postgrad &lt;- data$Postgrad[2] / data$Total[4] P_notsure_HS &lt;- data$HS[3] / data$Total[1] P_notsure_college &lt;- data$college[3] / data$Total[2] P_notsure_Bachelors &lt;- data$Bachelors[3] / data$Total[3] P_notsure_Postgrad &lt;- data$Postgrad[3] / data$Total[4] # Total probabilities for education levels P_HS &lt;- (913 + 277 + 408) / data$Total[4] P_college &lt;- (838 + 200 + 213) / data$Total[4] P_Bachelors &lt;- (686 + 117 + 81) / data$Total[4] P_Postgrad &lt;- (570 + 60 + 40) / data$Total[4] # Posterior Probabilities using Bayes&#39; Theorem P_iterative_post &lt;- (P_iterative_Postgrad * P_iterative) / P_Postgrad P_unchanging_post &lt;- (P_unchanging_Postgrad * P_unchanging) / P_Postgrad P_notsure_post &lt;- (P_notsure_Postgrad * P_notsure) / P_Postgrad # Result in a table result_table &lt;- data.frame( &quot;Education Level&quot; = c(&quot;HS&quot;, &quot;College&quot;, &quot;Bachelors&quot;, &quot;Postgrad&quot;), &quot;Iterative Posterior&quot; = c(P_iterative_HS, P_iterative_college, P_iterative_Bachelors, P_iterative_Postgrad), &quot;Unchanging Posterior&quot; = c(P_unchanging_HS, P_unchanging_college, P_unchanging_Bachelors, P_unchanging_Postgrad), &quot;Not Sure Posterior&quot; = c(P_notsure_HS, P_notsure_college, P_notsure_Bachelors, P_notsure_Postgrad) ) knitr::kable(result_table, caption = &quot;Posterior Probabilities for Scientific Responses by Education Level&quot;) Table 2.2: Posterior Probabilities for Scientific Responses by Education Level Education.Level Iterative.Posterior Unchanging.Posterior Not.Sure.Posterior HS 0.3036249 0.0921184 0.1356834 College 1.2813456 0.3058104 0.3256881 Bachelors 0.9245283 0.1576819 0.1091644 Postgrad 0.1294572 0.0136271 0.0090847 2.3 Applications of Bayesian Thinking Bayesian thinking has become the cornerstone statistical analysis method across various fields, from health science and finance to artificial intelligence and machine learning. Some of the most notable areas where Bayesian methods are routinely applied include: Health Sciences: In clinical trials or diagnosis, Bayesian analysis help update the probability of a disease given new test results, facilitating better decision-making (e.g., Spiegler et al., 2015). Machine Learning: In machine learning, Bayesian models are used for tasks such as classification, regression, and parameter estimation. Techniques like Bayesian neural networks integrate uncertainty into predictions, providing more robust models. Economics and Finance: Economists use Bayesian methods for modeling market behaviors and forecasting economic trends, with a focus on how beliefs evolve in response to new data (e.g., Berger, 1985). Robotics and Control Systems: Bayesian methods are integral in robot navigation, where robots continually update their belief about the environment based on sensor data (Thrun et al., 2005). Bayesian methods are also invaluable for decision theory. For instance, in situations involving risk and uncertainty, such as investment decisions or insurance underwriting, Bayes’ theorem can help quantify and incorporate uncertainty, leading to more informed choices. 2.4 Challenges Despite its many advantages, Bayesian thinking is not without its challenges. One common criticism is the subjectivity inherent in choosing priors. Critics argue that subjective priors can lead to biased conclusions, particularly if they are poorly chosen or overly informative. However, Bayesian methods include techniques like robustness analysis and sensitivity analysis to assess the influence of priors on the final outcome. Another challenge lies in the computational complexity of calculating the posterior. While modern algorithms such as Markov Chain Monte Carlo (MCMC) and variational inference have greatly improved the feasibility of Bayesian analysis, these methods can still be resource-intensive, especially for large datasets or highly complex models. References Berger, J. O. (1985). Statistical Decision Theory and Bayesian Analysis (2nd ed.). Springer-Verlag. Spiegler, T., et al. (2015). “Bayesian Decision Making in Clinical Medicine.” Journal of Clinical Epidemiology, 68(5), 621-632. McElreath, R. (2016). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9781315372495 "],["parameters-priors-and-posteriors.html", "Chapter 3 Parameters, Priors and Posteriors 3.1 Introduction 3.2 Parameter(s) 3.3 Priors 3.4 Posterior distributions", " Chapter 3 Parameters, Priors and Posteriors 3.1 Introduction The basic difference of Bayesian thinking from the frequentist approach is that the parameter is considered as random process with a distribution function. This distribution is then reflect the degree of our belief about the parameter before data is observed. Prior distribution satisfies the regularity condition of a probability distribution, non-negativity (because probability can not be negative), summed or integrated to 1 (certainty) and defined. Priors satisfying these conditions are referred “Proper” prior, otherwise “improper” prior. In this section different types of prior distribution is explored, how to graphically display and combine with likelihood to derive the posterior distribution. Objective priors are intended to be neutral and based on formal criteria, while subjective priors are more personalized and can incorporate individual expertise or prior knowledge. 3.2 Parameter(s) A parameter is measure or characteristic that can describe or classify a particular system such as event, object, or population data. Any model expressed in terms of parameters is a parametric models. In the simple linear regression model \\(y=\\alpha + \\beta * x + \\epsilon\\); \\(\\alpha\\), \\(\\beta\\) and \\(\\sigma^2_\\epsilon=var(\\epsilon)\\) are considered as parameters and unknown. 3.2.1 Identifying parameters in a distribution In the context of probability distributions, a parameter is a numerical characteristic that defines the shape, location, or scale of a distribution. For the normal distribution, the two key parameters are: Mean (\\(\\mu\\)) – Determines the of the distribution. Changing the mean shifts the distribution without affecting its shape. Variance (\\(\\sigma^2\\)) – Controls the of the distribution. A larger variance results in a wider, flatter distribution, while a smaller variance makes the distribution more peaked and concentrated around the mean. Activity 2.1: Simulate a normal data with unknown mean and known variance, i.e., \\((\\mu, \\sigma^2)\\). set.seed(123) # For reproducibility x_vals &lt;- seq(from = -20, to = 20,length.out = 500) norm_dat &lt;- data.frame( x = rep(x_vals, 3), pdf = c(dnorm(x_vals, mean = 0, sd = 2), dnorm(x_vals, mean = 5, sd = 2), dnorm(x_vals, mean = 10, sd = 2)), dist = rep(c(&quot;N(0,4)&quot;, &quot;N(5,4)&quot;, &quot;N(10,4)&quot;), each = length(x_vals)) ) head(norm_dat) ## x pdf dist ## 1 -20.00000 3.847299e-23 N(0,4) ## 2 -19.91984 5.739487e-23 N(0,4) ## 3 -19.83968 8.548551e-23 N(0,4) ## 4 -19.75952 1.271201e-22 N(0,4) ## 5 -19.67936 1.887289e-22 N(0,4) ## 6 -19.59920 2.797466e-22 N(0,4) library(ggplot2) ggplot(norm_dat) + geom_line(aes(x = x, y = pdf, color = dist, group = dist), linewidth = 1) + scale_x_continuous(limits = c(-10, 20)) + labs(title = &quot;Distribution of varied mean, constant variance&quot;, x = &quot;x&quot;, y = &quot;Density&quot;, color = &quot;Simulated Data&quot;) + theme_bw() + theme(legend.position = c(0.85, 0.8)) Figure 3.1: Likelihood function for normal distribution with random mean The density plot in Figure 3.1 illustrates the density functions of three simulated normal data with the same variance but different means. All three distributions have the same shape because they share the same variability (\\(\\sigma^2=4\\)). # Generate data set.seed(123) # For reproducibility x_vals &lt;- seq(-5, 15, length.out = 300) # Common x-range norm_dat_var &lt;- data.frame( x = rep(x_vals, 3), pdf = c(dnorm(x_vals, mean = 5, sd = 1), dnorm(x_vals, mean = 5, sd = 2), dnorm(x_vals, mean = 5, sd = 3)), dist = rep(c(&quot;N(5,1)&quot;, &quot;N(5,4)&quot;, &quot;N(5,9)&quot;), each = length(x_vals)) ) head(norm_dat_var) ## x pdf dist ## 1 -5.000000 7.694599e-23 N(5,1) ## 2 -4.933110 1.498692e-22 N(5,1) ## 3 -4.866221 2.906000e-22 N(5,1) ## 4 -4.799331 5.609651e-22 N(5,1) ## 5 -4.732441 1.078035e-21 N(5,1) ## 6 -4.665552 2.062466e-21 N(5,1) Plot the density functions ggplot(norm_dat_var, aes(x = x, y = pdf, color = dist, group = dist)) + geom_line(linewidth = 1) + scale_x_continuous(limits = c(-5, 15)) + labs(title = &quot;Effect of Variance on Normal Distributions&quot;, x = &quot;x&quot;, y = &quot;Density&quot;, color = &quot;Simulated Data&quot;) + theme_bw() + theme(legend.position = c(0.8, 0.8)) Figure 3.2: Likelihood function for normal distribution with random variance Similarly, the plot in figure 3.2 illustrates the density function of normal data with varying variance but same mean. We can easily observe that as variance increases, the density curve flattens because probability mass is spread out over a larger range. The highest peak corresponds to the smallest variance because values are more concentrated near the mean. As variance increases, the distribution becomes wider and flatter. Key insights When we kept variance constant and changed the mean, the distribution shifted along the x-axis but retained its shape. When we kept mean constant and changed the variance, the shape of the distribution changed, higher variance made the distribution more spread out, while lower variance made it more concentrated. This information proves that mean and variance are the two parameters describing the location and shape of a normal distribution. Additionally, consider a random variable \\(y\\) follows binomial distribution with parameter \\(\\theta\\), i.e., \\(y|\\theta, n \\sim Bin(n, \\theta)\\), where \\(n\\) represent the number of independent trials performed, and \\(\\theta\\) represent the probability of getting success. The probability function of \\(y\\) is given by \\[ P(y= y|\\theta, n) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}. \\] Here \\(\\theta\\) play the role of a parameter and different value result different likelihood value. Activity 2.2: Simulate binomial data with \\(n=30\\) and plot the density function of \\(y\\) for three different values of \\(\\theta\\). # Parameters library(dplyr) n &lt;- 30 y &lt;- 0:n theta &lt;- c(0.10, 0.50, 0.90) colors &lt;- c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;) # Create data frame df &lt;- expand.grid(y = y, theta = theta) %&gt;% mutate(prob = dbinom(y, size = n, prob = theta), group = factor(theta, labels = c(&quot;Bin(30, 0.10)&quot;, &quot;Bin(30, 0.50)&quot;, &quot;Bin(30, 0.90)&quot;))) # Plot ggplot(df, aes(x = y, y = prob, color = group)) + #geom_point() + geom_line(linewidth = 1) + labs(y = &quot;P(Y=y)&quot;, color = &quot;Distribution&quot;) + scale_color_manual(values = colors) + scale_x_continuous(limits = c(-1, 35)) + labs(title = expression(&quot;Effect of &quot; * theta * &quot; on binomial distributions&quot;)) + theme_bw() Figure 3.3: Binomial distribution with different \\(\\theta\\). Activity 2.3: Simulate binomial data with \\(n=30\\) and \\(y=7\\), and plot the likelihood function of \\(y\\) when for different value of \\(\\theta\\). # Simulaiton setting n &lt;- 30 # Number of trials y &lt;- 7 # Number of successes # Likelihood function for Binomial distribution likeld_func &lt;- function(theta, n, y) { choose(n, y) * (theta^y) * ((1 - theta)^(n - y)) } # Possible Values of theta ranges from 0 to 1 theta_values &lt;- seq(0, 1, length.out = 100) # Use he sapply function to compute the likelihood function for each value of theta and #store the result likelihood_values likeld_values &lt;- sapply(theta_values, likeld_func, n = n, y = y) #Create a dataframe df &lt;- data.frame(Theta = theta_values, Likelihood = likeld_values) #Print the first 5 rows of the datarame. head(df) ## Theta Likelihood ## 1 0.00000000 0.000000e+00 ## 2 0.01010101 1.729335e-08 ## 3 0.02020202 1.748393e-06 ## 4 0.03030303 2.353783e-05 ## 5 0.04040404 1.385933e-04 ## 6 0.05050505 5.180956e-04 The likelihood function is produced as follows: library(ggplot2) library(gridExtra) ggplot(df, aes(x = Theta, y = Likelihood)) + geom_line(color = &quot;blue&quot;, linewidth = 1) + labs(x = expression(theta[c]), y = expression(&quot;Likelihood function for Binom(n=18, y=7, &quot; * theta[c] * &quot;)&quot;), title = &quot;&quot;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5)) + theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14)) Figure 3.4: Likelihood function for the binomial distribution with n=30 and y=7 Figure 3.4 show the likelihood distribution of the observed data depends on its parameter \\(\\theta\\). Activity 2.4: Emergency Calls Suppose that a hospital receives emergency calls at an average of 10 calls per hour during a given day. If we assume that the calls arrive independently (meaning previous calls do not influence future calls), the number of calls follows a poisson process with a rate of \\(\\lambda\\) (calls/hour). Based on this information, simulate 1000 hours of emergency calls with \\(\\lambda=10\\) and analyze the number of calls received per hour. # Set seed for reproducibility set.seed(123) # Define parameters lambda &lt;- 10 n_hours &lt;- 1000 # Simulate Poisson distributed call arrivals calls_per_hour &lt;- rpois(n_hours, lambda) # Compute Poisson PMF for comparison x_vals &lt;- 0:max(calls_per_hour) poisson_probs &lt;- dpois(x_vals, lambda) # Create data frame for plotting df &lt;- data.frame(Calls=x_vals, Prob=poisson_probs) head(df) ## Calls Prob ## 1 0 4.539993e-05 ## 2 1 4.539993e-04 ## 3 2 2.269996e-03 ## 4 3 7.566655e-03 ## 5 4 1.891664e-02 ## 6 5 3.783327e-02 Plot the histogram of simulated data ggplot(data.frame(calls_per_hour), aes(x = calls_per_hour)) + geom_histogram(aes(y = ..density..), bins = 20, fill = &quot;skyblue&quot;, color = &quot;black&quot;, alpha = 0.6) + geom_line(data = df, aes(x = Calls, y = Prob), color = &quot;red&quot;, linewidth = 1) + labs(title = &quot;Poisson distribution of emergency calls per hour&quot;, x = &quot;Number of calls per hour&quot;, y = &quot;Probability&quot;) + theme_bw() Figure 3.5: Plot the empirical vs theoretical poisson distribution of emergency calls per hour The histogram closely matches the expected Poisson distribution, validating our assumption that the number of emergency calls per hour follows a Poisson process. This indicates that the Poisson model is appropriate for describing the arrival pattern of emergency calls. The Likelihood function of a poisson distribution is \\[ L(\\lambda|y) = \\prod^{n}_{i=1}\\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} \\] Direct simplification of the likelihood function, which is the product of the individual likelihood, is computationally inconvinient, we use the log-likelihood for better numerical stability: \\[ log\\, L(\\lambda|y) = \\sum^n_{i=1}\\left[-\\lambda + y_ilog\\,\\lambda-log\\, y_i!\\right]. \\] The following code computes and plot the likelihood function for different \\(\\lambda\\) Values. # Simulate possible lambda values from 5 to 15 lambda_vals &lt;- seq(5, 15, length.out = 100) #Compute the likelihood function log_likelihoods &lt;- sapply(lambda_vals, function(l) sum(dpois(calls_per_hour, l, log = TRUE))) # Normalize for better visualization log_likelihoods &lt;- log_likelihoods - max(log_likelihoods) # Create data frame df_lik &lt;- data.frame(lambda_vals, log_likelihoods) head(df_lik) ## lambda_vals log_likelihoods ## 1 5.000000 -1919.646 ## 2 5.101010 -1820.990 ## 3 5.202020 -1726.249 ## 4 5.303030 -1635.272 ## 5 5.404040 -1547.918 ## 6 5.505051 -1464.052 Plot log-likelihood function ggplot(df_lik, aes(x = lambda_vals, y = log_likelihoods)) + geom_line(color = &quot;blue&quot;, size = 1) + geom_vline(xintercept = mean(calls_per_hour), linetype = &quot;dashed&quot;, color = &quot;red&quot;, size = 1) + labs(title = &quot;Log-Likelihood function for poisson process&quot;, x = expression(&quot;Rate &quot; * lambda * &quot;&quot;), y = &quot;Log-likelihood&quot;) + theme_bw() Figure 3.6: Plot of log-likelihood function of a poisson process The log-likelihood function peaks near the observed sample mean (\\(\\sim 10\\)), which aligns with the MLE for the Poisson rate parameter \\(\\lambda\\). In a Poisson process, the MLE for \\(\\lambda\\) is given by: \\[ \\hat{\\lambda} = \\frac{1}{n} \\sum_{i=1}^{n} y_i = \\text{mean}(y) \\] Since the peak of the log-likelihood function corresponds to this estimate, it confirms that the observed data supports \\(\\lambda \\approx 10\\) as the most likely value for the true rate of emergency calls per hour. 3.2.2 Why this matters in Bayesian analysis Parameters are unknown in real-World problems: In Bayesian analysis, parameters like \\(\\mu\\) and \\(\\sigma^2\\) for normal variate are not fixed but uncertain. We use probability distributions to express our beliefs about them. Priors reflect initial beliefs: Before seeing any data, we assign prior distributions to parameters to encode what we believe about them. Posteriors update our knowledge: After observing data, Bayesian methods update our beliefs, leading to a posterior distribution that reflects both prior information and new evidence. This exploration of parameters lays the foundation for understanding how priors (initial beliefs about parameters) evolve into posteriors (updated beliefs) in Bayesian inference. 3.3 Priors As discussed in chapter 1, section 1.2.3, prior distribution can be specified for parameters. A prior can be: Non-Informative or Weakly informative Prior: Non-informative prior distribution is specified when there is no prior knowledge or information is available related to the parameter of interest. This prior is often vague, diffuse or flat relative to the likelihood function. It doesn’t favor any particular outcome over others, allowing the data to have more influence on the posterior distribution. In some cases, noninformative prior may lead to nonintegrable posterior function. This posteriors are referred improper posteriors. However, while noninformative priors are very popular in some applications, they are not always easy to construct (See., Gelman et al., 2014). Improper Prior: Improper prior is a prior distribution that does not integrate to one over its domain, that is; \\[ \\int p(\\theta)d\\theta = \\infty. \\] Improper priors are typically used as noninformative or flat priors and proper posterior distribution. For example, a flat prior \\(p(\\theta) = k\\) over an infinite range \\((-\\infty, \\infty)\\), is an improper prior. Often improper priors leads to improper posterior distributions and only valid in practive if the posterior is proper, i.e., the posterior \\(\\int p(y|\\theta)p(\\theta)d\\theta=1\\). Statistical inference based on the improper posterior distribution is invalid. Informative Prior: Informative prior is a prior specified to incorporate specific, substantive prior knowledge about the parameter based on previous studies, expert opinion, or other reliable sources. For instance, if we know from experience that a machine’s failure rate is low, we might use a prior that favors low failure rates. If previous studies suggest that a proportion \\(\\theta\\) (e.g., success rate) is likely around 70%, we might use \\[ \\theta \\sim Beta(7, 3), \\] which reflects that the prior belief is based on 7 sucesses and 3 failures. If we have prior knowledge that the mean of a parameter, \\(\\mu\\), is likeliy around 10 with high confidence, based on prior studies. We can specify a normal prior \\[ \\mu\\sim \\mathcal{N}(10, 2^2), \\] where the mean is 10, and the standard deviation is 2, reflecting how confident we are in the prior belief. It is a prior that dominate the likelihood and has an impact on the posterior distribution. Conjugate Priors: A \\(conjugate\\) \\(prior\\) is a specific type of prior distribution when combined with a specific likelihood, results in a posterior distribution of the same type as the prior. In short, prior distribution and the derived posterior distribution belong to the same family of distribution. For example, suppose a random variable follows binomial distribution, in short, \\(y\\sim Bin(m \\theta)\\) where \\(n\\) is the number of trials, and \\(\\theta\\) is the success probability. The distribution of \\(y\\) is \\[ p(y|\\theta)\\propto \\theta^y(1-\\theta)^{n-y}. \\] Since, \\(\\theta\\) is assumed to be a random process, the conjugate prior is \\[ \\theta\\sim Beta(\\alpha, \\beta). \\] The updated posterior, i.e., combining likelihood and prior, the posterior distribution is \\[ \\theta|y \\sim Beta(\\alpha + y, \\beta+n-y), \\] which is recognized as a Beta distribution with shape and scale parameters \\(\\alpha+y\\) and \\(\\beta+n-y\\), respectively. Here we can easily observe that both prior and the posterior distributions follow Beta distribution. Hence Beta Prior is the natural conjugate prior for \\(\\theta\\), the probability of success. If \\(\\theta\\) represents the parameter of interest, the prior distribution for \\(\\theta\\) is denoted as \\(p(\\theta)\\). If there are multiple parameters, the joint prior distribution is written as \\(p(\\theta_1, \\theta_2)\\). 3.3.1 Uniform or Discrete Prior If a distribution function has a constant trend over the range space of the parameter, then the parameter has discrete distribution function. If the parameter \\(\\theta\\) takes discrete or countably infinite set of values, a discrete prior can be specified. For example, if a population of successes and failures where \\(\\theta\\) represent the proportion of success, \\(\\theta\\) would take one of the discrete values in the set \\({0.0, 0.01, \\ldots, 0.99, 1.0}\\), and the prior would be a probability distribution over these values. library(ggplot2) p &lt;- seq(0, 1, by = 0.01) prior &lt;- 1 / 101 + 0 * p df_prior &lt;- cbind(p=p, prior=prior) head(df_prior) ## p prior ## [1,] 0.00 0.00990099 ## [2,] 0.01 0.00990099 ## [3,] 0.02 0.00990099 ## [4,] 0.03 0.00990099 ## [5,] 0.04 0.00990099 ## [6,] 0.05 0.00990099 ggplot(df_prior, aes(x = p, y = prior)) + geom_linerange(aes(ymin = 0, ymax = prior), color = &quot;blue&quot;) + labs(title = &quot;&quot;, x = expression(theta), y = &quot;Prior probability&quot;) + ylim(0, 0.015) + theme_bw() Figure 3.7: Discrete prior distribution of \\(\\theta\\) Uniform or discrete prior assumes that all values within a range are equally likely, and used when no prior information is available towards the parameter of interest. 3.3.2 Normal or Gaussian Prior A normal prior is a prior with a normal distribution centered around its mean value with some uncertainty. It is used when we expect values to cluster around a mean. x_vals &lt;- seq(-4, 4, length.out = 100) data &lt;- data.frame(x = x_vals, density = dnorm(x_vals, mean = 0, sd = 1)) ggplot(data, aes(x = x, y = density)) + geom_line(color = &quot;blue&quot;, size = 1) + labs(title = &quot;&quot;, x = expression(theta), y = &quot;Density&quot;) + theme_minimal() Figure 3.8: Normal prior distribution of \\(\\theta\\) 3.3.3 Beta Prior In probability theory, Beta distribution is a family of continuous probability distribution often used to model the uncertainty about the probability of success of an experiment. It is parametrized by shape parameters \\(\\alpha\\) and \\(\\beta\\) both greater than 0, which shape the distribution. # Create a sequence of x values from 0 to 1 x_vals &lt;- seq(0, 1, length.out = 100) # Compute different Beta densities for the given parameters data &lt;- data.frame( x = rep(x_vals, 6), density = c( dbeta(x_vals, shape1 = 0.5, shape2 = 0.5), # Beta(0.5, 0.5) dbeta(x_vals, shape1 = 1, shape2 = 1), # Beta(1, 1) dbeta(x_vals, shape1 = 2, shape2 = 2), # Beta(2, 2) dbeta(x_vals, shape1 = 1, shape2 = 3), # Beta(1, 3) dbeta(x_vals, shape1 = 5, shape2 = 2), # Beta(5, 2) dbeta(x_vals, shape1 = 2, shape2 = 5) # Beta(2, 5) ), Beta_Type = rep(c(&quot;Beta(0.5,0.5)&quot;, &quot;Beta(1,1)&quot;, &quot;Beta(2,2)&quot;, &quot;Beta(1,3)&quot;, &quot;Beta(5,2)&quot;, &quot;Beta(2,5)&quot;), each = 100) ) # Plot using ggplot2 library(ggplot2) ggplot(data, aes(x = x, y = density, color = Beta_Type)) + geom_line(size = 1) + labs(title = &quot;&quot;, x = expression(theta), y = &quot;Density&quot;, color = &quot;Distribution&quot;) + theme_bw() + scale_color_manual(values = c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;orange&quot;, &quot;brown&quot;)) Figure 3.9: Beta prior distribution with different \\(\\alpha\\) and \\(\\beta\\) values The plot in figure 3.9 show various prior beliefs about probabilities before observing data. Forexample, the \\(Beta(0.5, 0.5)\\) prior refers to the U-Shaped Jeffreys Prior with higher densities near 0 and 1. It is often used to define a noninformative prior with a strong prior belief that the probability is either very low or very high. The \\(Beta(1,1)\\) refers to the Uniform Prior or flat prior distribution. It is often used to define a noninformative prior with a strong prior belief to assigns equal probability to the parameter. The \\(Beta(1, 3)\\), \\(Beta(2,5)\\), and \\(Beta(5, 2)\\) priors express preference for certain probability ranges, whereas the \\(Beta(2, 2)\\) prior is a symmetric or normal prior favoring moderate values. If we assume that \\(\\alpha-1\\) as the number of successes and \\(\\beta-1\\) as the number of failures, \\(Beta(2, 2)\\) means you getting \\(1\\) success and \\(1\\) failure, so that the probability of the success would become the highest at 0.5. Each of the priors shown in figure 3.9 can be used depending on our beliefs before observing data. In summary Beta prior is a conjugate prior with Bernoulli, binomial, negative binomial, and geometric distributions. Dirichlet prior is conjugate prior with Multinomial distribution Normal prior is conjugate prior with Normal distribution when used for the mean and the variance is known Gamma (Inverse-Gamma) prior is conjugate prior with Normal distribution with known mean when used for the precision (variance) the variance. Precision is inverse of a variance parameter. 3.4 Posterior distributions The mechanism that underpins all of Bayesian statistical analysis is Bayes’ rule9, which describes how to update uncertainty in light of new information, evidence, or data. Example 1.4: Continuing example 1.4 in Chapter 1, find the posterior distribution of the proportion of left-handed students in the population assuming (i) uninformative prior, (ii) informative prior assuming 5 - 20% of people are left-handed according to the literature. Solution - Recall that the random variable \\(y\\) has a binomial distribution: \\[ y \\sim Bin(n=30, \\theta),\\,\\, \\] with the likelihood function: \\[ L(\\theta|y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}, \\] The natural conjugate prior for a binomial parameter \\(\\theta\\) is the \\(Beta(\\alpha, \\beta)\\) prior as discussed in the section 2.3. The posterior distribution of \\(\\theta|y\\) (the derivation is discussed in the next chapter), has a Beta distribution, i.e., \\(\\theta|y\\sim Beta(y + \\alpha, n - y + \\beta)\\). The following code simulate and plot both prior and prior distribution. # Given data y &lt;- 7 # Left-handed students n &lt;- 30 # Total students # Create a sequence of p values for density plotting p_seq &lt;- seq(0, 1, length.out = 1000) likelihood &lt;- dbinom(y, n, p_seq) # Likelihood (up to scale factor) likelihood &lt;- likelihood / max(likelihood) p_hat &lt;- y / n # MLE estimate p_hat ## [1] 0.2333333 Uninformative (Uniform) prior # Define priors alpha_unif &lt;- 1; beta_unif &lt;- 1 # # Compute posterior parameters post_alpha_unif &lt;- alpha_unif + y post_beta_unif &lt;- beta_unif + (n - y) # Compute densities prior_unif &lt;- dbeta(p_seq, alpha_unif, beta_unif) posterior_unif &lt;- dbeta(p_seq, post_alpha_unif, post_beta_unif) Create dataframe for noninformative prior df &lt;- data.frame( p = rep(p_seq, 3), Density = c(prior_unif, likelihood, posterior_unif), Distribution = rep(c(&quot;Prior&quot;, &quot;Likelihood&quot;, &quot;Posterior&quot;), each = length(p_seq)) ) head(df) ## p Density Distribution ## 1 0.000000000 1 Prior ## 2 0.001001001 1 Prior ## 3 0.002002002 1 Prior ## 4 0.003003003 1 Prior ## 5 0.004004004 1 Prior ## 6 0.005005005 1 Prior Plot for uninformative prior library(ggplot2) ggplot(df, aes(x = p, y = Density, color = Distribution)) + geom_line(size = 1) + geom_vline(xintercept = p_hat, linetype = &quot;dashed&quot;, color = &quot;black&quot;, label=&quot;MLE&quot;) + geom_vline(xintercept = (post_alpha_unif / (post_alpha_unif + post_beta_unif)), linetype = &quot;dotted&quot;, color = &quot;blue&quot;, label=&quot;Posterior Mean&quot;) + theme_minimal() + labs(title = &quot;Posterior distribution with noninformative prior&quot;, x = &quot;Proportion of left-handed students&quot;) Informative prior Create a dataframe for informative prior alpha_inf &lt;- 5; beta_inf &lt;- 25 # Informative prior (centered around 10%) post_alpha_inf &lt;- alpha_inf + y post_beta_inf &lt;- beta_inf + (n - y) prior_inf &lt;- dbeta(p_seq, alpha_inf, beta_inf) posterior_inf &lt;- dbeta(p_seq, post_alpha_inf, post_beta_inf) df_inf &lt;- data.frame( p = rep(p_seq, 3), Density = c(prior_inf, likelihood, posterior_inf), Distribution = rep(c(&quot;Prior&quot;, &quot;Likelihood&quot;, &quot;Posterior&quot;), each = length(p_seq)) ) head(df_inf) ## p Density Distribution ## 1 0.000000000 0.000000e+00 Prior ## 2 0.001001001 5.819976e-07 Prior ## 3 0.002002002 9.090589e-06 Prior ## 4 0.003003003 4.492596e-05 Prior ## 5 0.004004004 1.386060e-04 Prior ## 6 0.005005005 3.303250e-04 Prior # Plot for informative prior ggplot(df_inf, aes(x = p, y = Density, color = Distribution)) + geom_line(size = 1) + geom_vline(xintercept = p_hat, linetype = &quot;dashed&quot;, color = &quot;black&quot;, label=&quot;MLE&quot;) + geom_vline(xintercept = (post_alpha_inf / (post_alpha_inf + post_beta_inf)), linetype = &quot;dotted&quot;, color = &quot;blue&quot;, label=&quot;Posterior Mean&quot;) + theme_minimal() + labs(title = &quot;Posterior distribution with informative prior&quot;, x = &quot;Proportion of left-handed students&quot;) Activity: Do people prefer to use the word “data” as singular or plural? Data journalists at \\(FiveThirtyEight\\) conducted a poll to address this question (and others). Rather than simply ask whether the respondent considered “data” to be singular or plural, they asked which of the following sentences they prefer: Some experts say it’s important to drink milk, but the data is inconclusive. Some experts say it’s important to drink milk, but the data are inconclusive. Suppose we wish to study the opinions of students in Cal Poly statistics classes regarding this issue. That is, let \\(\\theta\\) represent the population proportion of students in Cal Poly statistics classes who prefer to consider data as a singular noun, as in option a) above. To illustrate ideas, we’ll start with a prior distribution which places probability 0.01, 0.05, 0.15, 0.30, 0.49 on the values 0.1, 0.3, 0.5, 0.7, 0.9, respectively. Before observing any data, suppose we plan to randomly select a single Cal Poly statistics student. Consider the unconditional prior probability that the selected student prefers data as singular. (This is called a prior predictive probability.) Explain how you could use simulation to approximate this probability. Compute the prior predictive probability from the previous part. Before observing any data, suppose we plan to randomly select a sample of 35 Cal Poly statistics students. Consider the unconditional prior distribution of the number of students in the sample who prefer data as singular. (This is called a prior predictive distribution.) Explain how you could use simulation to approximate this distribution. In particular, how could you use simulation to approximate the prior predictive probability that at least 34 students in the sample prefer data as singular? Compute and interpret the prior predictive probability that at least 34 students in a sample of size 35 prefer data as singular. For the remaining parts, suppose that 31 students in a sample of 35 Cal Poly statistics students prefer data as singular. Find the posterior distribution of \\(\\theta\\). Now suppose we plan to randomly select an additional Cal Poly statistics student. Consider the posterior predictive probability that this student prefers data as singular. Explain how you could use simulation to estimate this probability. Compute the posterior predictive probability from the previous part. Suppose we plan to collect data on another sample of 35 Cal Poly statistics students. Consider the posterior predictive distribution of the number of students in the new sample who prefer data as singular. Explain how you could use simulation to approximate this distribution. In particular, how could you use simulation to approximate the prior predictive probability that at least 34 students in the sample prefer data as singular? (Of course, the sample size of the new sample does not have to be 35. However, we’re keeping it the same so we can compare the prior and posterior predictions.) Compute and interpret the posterior predictive probability that at least 34 students in a sample of size 35 prefer data as singular. Solution If we knew what \\(\\theta\\) was, this probability would just be \\(\\theta\\). For example, if \\(\\theta = 0.9\\), then there is a probability of 0.9 that a randomly selected student prefers data singular. If \\(\\theta\\) were 0.9, we could approximate the probability by constructing a spinner with 90% of the area marked as ``success”, spinning it many times, and recording the proportion of spins that land on success, which should be roughly 90%. However, 0.9 is only one possible value of \\(\\theta\\). Since we don’t know what \\(\\theta\\) is, we need to first simulate a value of it, giving more weight to \\(\\theta\\) values with high prior probability. Therefore, we Simulate a value of \\(\\theta\\) from the prior distribution Given the value of \\(\\theta\\), construct a spinner that lands on success with probability \\(\\theta\\). Spin the spinner once and record the result, success or not. Repeat steps 1 and 2 many times, and find the proportion of repetitions which result in success. This proportion approximates the unconditional prior probability of success. Use the law of total probability, where the weights are given by the prior probabilities. \\[ 0.1(0.01) + 0.3(0.05) + 0.5(0.15) + 0.7(0.30) + 0.9(0.49) = 0.742 \\] (This calculation is equivalent to the expected value of \\(\\theta\\) according to its prior distribution, that is, the prior mean.) If we knew what \\(\\theta\\) was, we could construct a spinner that lands on success with probability \\(\\theta\\), spin it 35 times, and count the number of successes. Since we don’t know what \\(\\theta\\) is, we need to first simulate a value of it, giving more weight to \\(\\theta\\) values with high prior probability. Therefore, we Simulate a value of \\(\\theta\\) from the prior distribution. Given the value of \\(\\theta\\), construct a spinner that lands on success with probability \\(\\theta\\). Spin the spinner 35 times and count \\(y\\), the number of spins that land on success. Repeat steps 1 and 2 many times, and record the number of successes (out of 35) for each repetition. Summarize the simulated \\(y\\) values to approximate the prior predictive distribution. To approximate the prior predictive probability that at least 34 students in a sample of size 35 prefer data as singular, count the number of simulated repetitions that result in at least 34 successes (\\(y \\geq 34\\)) and divide by the total number of simulated repetitions. If we knew \\(\\theta\\), the probability of at least 34 (out of 35) successes is, from a Binomial distribution, \\[ \\binom{35}{34} \\theta^{34}(1 - \\theta) + \\theta^{35} \\] Use the law of total probability again: \\[\\begin{aligned} \\left(\\binom{35}{34} (0.1)^{34} (1 - 0.1) + 0.1^{35} \\right)(0.01) + \\left(\\binom{35}{34} (0.3)^{34} (1 - 0.3) + 0.3^{35} \\right)(0.05) \\\\ + \\left(\\binom{35}{34} (0.5)^{34} (1 - 0.5) + 0.5^{35} \\right)(0.15) + \\left(\\binom{35}{34} (0.7)^{34} (1 - 0.7) + 0.7^{35} \\right)(0.30) \\\\ + \\left(\\binom{35}{34} (0.9)^{34} (1 - 0.9) + 0.9^{35} \\right)(0.49) = 0.06 \\end{aligned}\\] According to this model, about 6% of samples of size 35 would result in at least 34 successes. The value 0.06 accounts for both (1) our prior uncertainty about \\(\\theta\\), and (2) sample-to-sample variability in the number of successes \\(y\\). The likelihood is \\(\\binom{35}{31} \\theta^{31} (1 - \\theta)^4\\), a function of \\(\\theta\\); \\(\\texttt{dbinom(31, 35, \\theta)}\\). The posterior places almost all probability on \\(\\theta = 0.9\\), due to both its high prior probability and high likelihood. library(dplyr) library(knitr) library(janitor) ## ## Attaching package: &#39;janitor&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## chisq.test, fisher.test theta = seq(0.1, 0.9, 0.2) # prior prior = c(0.01, 0.05, 0.15, 0.30, 0.49) # data n = 35 # sample size y = 31 # sample count of success # likelihood, using binomial likelihood = dbinom(y, n, theta) # function of theta # posterior product = likelihood * prior posterior = product / sum(product) # bayes table bayes_table = data.frame(theta, prior, likelihood, product, posterior) bayes_table %&gt;% adorn_totals(&quot;row&quot;) %&gt;% kable(digits = 4, align = &#39;r&#39;) theta prior likelihood product posterior 0.1 0.01 0.0000 0.0000 0.0000 0.3 0.05 0.0000 0.0000 0.0000 0.5 0.15 0.0000 0.0000 0.0000 0.7 0.30 0.0067 0.0020 0.0201 0.9 0.49 0.1998 0.0979 0.9799 Total 1.00 0.2065 0.0999 1.0000 The simulation would be similar to the prior simulation, but now we simulate \\(\\theta\\) from its posterior distribution rather than the prior distribution. Simulate a value of \\(\\theta\\) from the posterior distribution. Given the value of \\(\\theta\\), construct a spinner that lands on success with probability \\(\\theta\\). Spin the spinner once and record the result, success or not. Repeat steps 1 and 2 many times, and find the proportion of repetitions which result in success. This proportion approximates the unconditional posterior probability of success. Use the law of total probability, where the weights are given by the posterior probabilities. \\[ 0.1(0.0000) + 0.3(0.0000) + 0.5(0.0000) + 0.7(0.0201) + 0.9(0.9799) = 0.8960 \\] (This calculation is equivalent to the expected value of \\(\\theta\\) according to its posterior distribution, that is, the posterior mean.) The simulation would be similar to the prior simulation, but now we simulate \\(\\theta\\) from its posterior distribution rather than the prior distribution. Simulate a value of \\(\\theta\\) from the posterior distribution. Given the value of \\(\\theta\\), construct a spinner that lands on success with probability \\(\\theta\\). Spin the spinner 35 times and count the number of spins that land on success. Repeat steps 1 and 2 many times, and record the number of successes (out of 35) for each repetition. Summarize the simulated values to approximate the posterior predictive distribution. To approximate the posterior predictive probability that at least 34 students in a sample of size 35 prefer data as singular, count the number of simulated repetitions that result in at least 34 successes and divide by the total number of simulated repetitions. Since the posterior probability that \\(\\theta\\) equals 0.9 is close to 1, the posterior predictive distribution would be close to, but not quite, the$ Binom(35, 0.9)$ distribution. Use the law of total probability again, but with the posterior probabilities rather than the prior probabilities as the weights. \\[ \\left(\\binom{35}{34} (0.1)^{34} (1 - 0.1) + 0.1^{35} \\right)(0.0000) + \\left(\\binom{35}{34} (0.3)^{34} (1 - 0.3) + 0.3^{35} \\right)(0.0000) \\\\ + \\left(\\binom{35}{34} (0.5)^{34} (1 - 0.5) + 0.5^{35} \\right)(0.0000) + \\left(\\binom{35}{34} (0.7)^{34} (1 - 0.7) + 0.7^{35} \\right)(0.0201) \\\\ + \\left(\\binom{35}{34} (0.9)^{34} (1 - 0.9) + 0.9^{35} \\right)(0.9799) = 0.1199 \\] According to this posterior model, about 12% of samples of size 35 would result in at least 34 successes. The value 0.12 accounts for both (1) our posterior uncertainty about \\(\\theta\\), after observing the sample data, and (2) sample-to-sample variability in the number of successes \\(y\\) for the yet-to-be-observed sample. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
